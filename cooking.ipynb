{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Yan Chun Shan, Solomon SID: 53660593"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Library/Python/2.7/site-packages/sklearn/qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "import IPython.utils.warn as warn\n",
    "random.seed(100)\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load heloper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cooking(fname):\n",
    "    # load the cooking dataset\n",
    "    # returns dictionary with data, target (cuisine type), item ids\n",
    "    \n",
    "    fp = open(fname, \"r\")\n",
    "    dataj = json.load(fp)\n",
    "    fp.close()\n",
    "    \n",
    "    data = []\n",
    "    ids  = []\n",
    "    target = []\n",
    "    for o in dataj:\n",
    "        if o.has_key('cuisine'):\n",
    "            target.append(o['cuisine'])\n",
    "        ids.append(o['id'])\n",
    "        data.append(o['ingredients'])\n",
    "\n",
    "    out = {\"data\": data, \"id\":ids}\n",
    "    if len(target) > 0:\n",
    "        out[\"target\"] =  target\n",
    "    return out\n",
    "\n",
    "\n",
    "# write a kaggle submission file for \"whats cooking\"\n",
    "def write_csv_kaggle_cooking(fname, ids, target):\n",
    "    # header\n",
    "    tmp = [['id', 'cuisine']]\n",
    "    \n",
    "    for i in range(len(ids)):\n",
    "        # add a row (id and class prediction)\n",
    "        tmp.append([ids[i], target[i]])\n",
    "        \n",
    "    # write CSV file\n",
    "    f = open(fname, 'wb')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tmp)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class MLA:\n",
    "    def __init__(self, train_predictors, train_target, test_predictors, test_target):\n",
    "        self.train_predictors = train_predictors\n",
    "        self.train_target = train_target\n",
    "        self.test_predictors = test_predictors\n",
    "        self.test_target = test_target\n",
    "        \n",
    "    def logicticRegression(self):\n",
    "        self.timer_start()\n",
    "        print 'build logictic regression model:'\n",
    "        params = {'C':[1, 10]}\n",
    "        self.classifier = LogisticRegression()\n",
    "        self.classifier = grid_search.GridSearchCV(self.classifier, params)\n",
    "        self.classifier.fit(self.train_predictors,self.train_target)\n",
    "        self.predictions = self.classifier.predict(test_predictors)\n",
    "        self.timer_end()\n",
    "        self.cal_acc()\n",
    "        \n",
    "        \n",
    "    def svm(self):\n",
    "        self.timer_start()\n",
    "#         Cs = logspace(0.1, 0.9, endpoint=False)\n",
    "#         avgscores = empty(Cs.shape)\n",
    "#         avgscores = empty(Cs.shape)\n",
    "#         for i,C in enumerate(Cs):\n",
    "#             # create the SVM classifier\n",
    "#             self.classifier = svm.SVC(kernel='linear', C=C)\n",
    "#             # calculate the scores for this classifier\n",
    "#             myscore = cross_validation.cross_val_score(self.classifier, train_predictors, train_target, cv=5)\n",
    "#             # record the average score\n",
    "#             avgscores[i] = mean(myscore)\n",
    "#         # pick the best C\n",
    "#         besti = argmax(avgscores)\n",
    "#         bestC = Cs[besti]\n",
    "#         print \"bestC =\", bestC\n",
    "        \n",
    "        print 'build svm classifier:'\n",
    "        self.classifier = svm.LinearSVC(C=0.8, penalty=\"l2\", dual=False)\n",
    "        self.classifier.fit(self.train_predictors,self.train_target).score(train_predictors, train_target)\n",
    "        self.predictions = self.classifier.predict(test_predictors)\n",
    "        self.timer_end()\n",
    "        self.cal_acc()\n",
    "        \n",
    "    def decision_tree(self):\n",
    "        self.timer_start()\n",
    "        print 'build decision tree model:'\n",
    "        self.classifier = tree.DecisionTreeClassifier()\n",
    "        self.classifier.fit(self.train_predictors,self.train_target)\n",
    "        self.predictions = self.classifier.predict(test_predictors)\n",
    "        self.timer_end()\n",
    "        self.cal_acc()\n",
    "    \n",
    "    def naive_bayes_gaussian(self):\n",
    "        self.timer_start()\n",
    "        print 'build naive bayes classifier:'\n",
    "        self.classifier = naive_bayes.GaussianNB()\n",
    "        self.classifier.fit(self.train_predictors,self.train_target)\n",
    "        self.predictions = self.classifier.predict(test_predictors)\n",
    "        self.timer_end()\n",
    "        self.cal_acc()\n",
    "        \n",
    "        \n",
    "    def naive_bayes_multinomial(self):\n",
    "        self.timer_start()\n",
    "        print 'build naive bayesmultinomial classifier:'\n",
    "        self.classifier = naive_bayes.MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "        self.classifier.fit(self.train_predictors,self.train_target)\n",
    "        self.predictions = self.classifier.predict(test_predictors)\n",
    "        self.timer_end()\n",
    "        self.cal_acc()\n",
    "        \n",
    "    def naive_bayes_bernoulli(self):\n",
    "        self.timer_start()\n",
    "        print 'build naive bayes bernoulli classifier:'\n",
    "        self.classifier = naive_bayes.BernoulliNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "        self.classifier.fit(self.train_predictors,self.train_target)\n",
    "        self.predictions = self.classifier.predict(test_predictors)\n",
    "        self.timer_end()\n",
    "        self.cal_acc()\n",
    "        \n",
    "    def randomForest(self):\n",
    "        self.timer_start()\n",
    "        print 'build random forest classifier:'\n",
    "        self.classifier = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=1, random_state=0)\n",
    "        self.classifier.fit(self.train_predictors,self.train_target)\n",
    "        self.predictions = self.classifier.predict(test_predictors)\n",
    "        self.timer_end()\n",
    "        self.cal_acc()\n",
    "    \n",
    "    def timer_start(self):     \n",
    "        self.start = time.time()\n",
    "    \n",
    "    def timer_end(self):     \n",
    "        self.end = time.time()\n",
    "        print \"Time: \", self.end - self.start    \n",
    "        \n",
    "    def cal_acc(self):\n",
    "        # calculate accuracy\n",
    "        Ncorrect = sum(self.test_target == self.predictions)\n",
    "        acc      = mean(self.test_target == self.predictions)\n",
    "        print \"number correct =\", Ncorrect\n",
    "        print \"test accuracy =\", acc\n",
    "    \n",
    "    def predict(self, predictors):\n",
    "        return self.classifier.predict(predictors)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load both train and test data from source \n",
    "traindata = load_cooking(\"train.json\")\n",
    "testdata  = load_cooking(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean ingredient data\n",
    "traindata['ingredient_plain'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in traindata['data']]\n",
    "testdata['ingredient_plain'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in testdata['data']] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create frequency term matrix\n",
    "vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                             ngram_range = ( 1 , 1 ),analyzer=\"word\", \n",
    "                             max_df = .57 , binary=False , token_pattern=r'\\w+' , sublinear_tf=False)\n",
    "\n",
    "traindata_sparse_matrix = vectorizer.fit_transform(traindata['ingredient_plain']).todense()\n",
    "testdata_sparse_matrix = vectorizer.transform(testdata['ingredient_plain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Partition data into training set and test set\n",
    "train_predictors, test_predictors, train_target, test_target = \\\n",
    "  cross_validation.train_test_split(traindata_sparse_matrix, traindata['target'], \n",
    "  train_size=0.6, test_size=0.4, random_state=4487)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimate the accuracy\n",
    "mla = MLA(train_predictors, train_target, test_predictors, test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build logictic regression model:\n",
      "Time:  38.7301559448\n",
      "number correct = 12501\n",
      "test accuracy = 0.785732243872\n"
     ]
    }
   ],
   "source": [
    "mla.logicticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build svm classifier:\n",
      "Time:  4.1739449501\n",
      "number correct = 12484\n",
      "test accuracy = 0.784663733501\n"
     ]
    }
   ],
   "source": [
    "mla.svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build decision tree model:\n",
      "Time:  45.7204201221\n",
      "number correct = 9646\n",
      "test accuracy = 0.606285355123\n"
     ]
    }
   ],
   "source": [
    "mla.decision_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build naive bayes classifier:\n",
      "Time:  29.3554518223\n",
      "number correct = 4187\n",
      "test accuracy = 0.263167818982\n"
     ]
    }
   ],
   "source": [
    "mla.naive_bayes_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build naive bayesmultinomial classifier:\n",
      "Time:  0.758901119232\n",
      "number correct = 10514\n",
      "test accuracy = 0.660842237586\n"
     ]
    }
   ],
   "source": [
    "mla.naive_bayes_multinomial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build naive bayes bernoulli classifier:\n",
      "Time:  3.3575758934\n",
      "number correct = 11354\n",
      "test accuracy = 0.713639220616\n"
     ]
    }
   ],
   "source": [
    "mla.naive_bayes_bernoulli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build random forest classifier:\n",
      "Time:  9.34719395638\n",
      "number correct = 10949\n",
      "test accuracy = 0.68818353237\n"
     ]
    }
   ],
   "source": [
    "mla.randomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build logictic regression model:\n",
      "Time:  44.2182929516\n",
      "number correct = 12501\n",
      "test accuracy = 0.785732243872\n"
     ]
    }
   ],
   "source": [
    "mla.logicticRegression()\n",
    "predictions = mla.predict(testdata_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "write_csv_kaggle_cooking(\"submission.csv\", testdata['id'], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
